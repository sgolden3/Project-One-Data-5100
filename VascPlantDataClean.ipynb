{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14593701-ac57-452a-8203-95757438fb2c",
   "metadata": {},
   "source": [
    "# Data Cleaning for San Juan and North Cascades Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ccabfbd-6b01-4ab7-ad09-b05cb4aaee94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import calendar\n",
    "\n",
    "tbl = pd.read_csv(\"/Users/carterwebb/Desktop/plants/raw_data/tbl_Plant_Collections.txt\", sep=None, engine=\"python\", encoding=\"latin1\")\n",
    "noca2002 = pd.read_csv(\"/Users/carterwebb/Desktop/plants/raw_data/no_ca/NOCA 2002.txt\", sep=None, engine=\"python\", encoding=\"latin1\")\n",
    "noca2003 = pd.read_csv(\"/Users/carterwebb/Desktop/plants/raw_data/no_ca/NOCA 2003.txt\", sep=None, engine=\"python\", encoding=\"latin1\")\n",
    "noca2004 = pd.read_csv(\"/Users/carterwebb/Desktop/plants/raw_data/no_ca/NOCA 2004.txt\", sep=None, engine=\"python\", encoding=\"latin1\")\n",
    "noca2005 = pd.read_csv(\"/Users/carterwebb/Desktop/plants/raw_data/no_ca/NOCA 2005.txt\", sep=None, engine=\"python\", encoding=\"latin1\")\n",
    "noca2006 = pd.read_csv(\"/Users/carterwebb/Desktop/plants/raw_data/no_ca/NOCA_2006_GIS.txt\", sep=None, engine=\"python\", encoding=\"latin1\")\n",
    "noca2007 = pd.read_csv(\"/Users/carterwebb/Desktop/plants/raw_data/no_ca/NOCA 2007.txt\", sep=None, engine=\"python\", encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5d25a4-fa4a-4057-93e7-2d7fb24cc4a5",
   "metadata": {},
   "source": [
    "## San Juans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e48b7a-28a6-4908-a682-94b6c9c561d5",
   "metadata": {},
   "source": [
    "### Reduce Size To a Minimal State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6d9481f-56e9-4a4f-9925-b8b1147b561d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl2 = tbl[[\n",
    "    \"Family\",\n",
    "    \"Scientific Name\",\n",
    "    \"Common Name\",\n",
    "    \"Coll Date\",\n",
    "    \"County\",\n",
    "    \"State\",\n",
    "    \"UTM Z/E/N\",\n",
    "    \"Elevation M\",\n",
    "    \"UTM_Y\",\n",
    "    \"UTM_X\",\n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8235a4-bb31-4b05-9028-3ebdc87d3c2c",
   "metadata": {},
   "source": [
    "### Split Scientific Name Up for Genus and Species Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "162cd092-40f6-4d60-bc70-45a91578bbec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7s/t5l3pg4j2j54njys9zrdzdxr0000gn/T/ipykernel_31894/1242335323.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tbl2[[\"Genus\", \"Species\"]] = tbl2[\"Scientific Name\"].str.split(n=1, expand=True);\n",
      "/var/folders/7s/t5l3pg4j2j54njys9zrdzdxr0000gn/T/ipykernel_31894/1242335323.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tbl2[[\"Genus\", \"Species\"]] = tbl2[\"Scientific Name\"].str.split(n=1, expand=True);\n",
      "/var/folders/7s/t5l3pg4j2j54njys9zrdzdxr0000gn/T/ipykernel_31894/1242335323.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tbl2[[\"Species\", \"Authority\"]] = tbl2[\"Species\"].str.split(n=1, expand=True)\n",
      "/var/folders/7s/t5l3pg4j2j54njys9zrdzdxr0000gn/T/ipykernel_31894/1242335323.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tbl2[[\"Species\", \"Authority\"]] = tbl2[\"Species\"].str.split(n=1, expand=True)\n"
     ]
    }
   ],
   "source": [
    "tbl2[[\"Genus\", \"Species\"]] = tbl2[\"Scientific Name\"].str.split(n=1, expand=True); \n",
    "tbl2[[\"Species\", \"Authority\"]] = tbl2[\"Species\"].str.split(n=1, expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3d5015-b0e0-460e-8395-6d7504deb36e",
   "metadata": {},
   "source": [
    "### Snake Case Naming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a39e27c-ae75-403d-856f-d34d3c0bb898",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl2 = tbl2.rename(columns={\n",
    "    \"Scientific Name\": \"scientific_name\",\n",
    "    \"Family\": \"family\",\n",
    "    \"Genus\": \"genus\",\n",
    "    \"Species\": \"species\",\n",
    "    \"Authority\": \"authority\",\n",
    "    \"Common Name\": \"common_name\",\n",
    "    \"Coll Date\": \"coll_date\",\n",
    "    \"County\": \"county\",\n",
    "    \"State\": \"state\",\n",
    "    \"UTM Z/E/N\": \"utm_zone\",\n",
    "    \"Elevation M\": \"elev_m\",\n",
    "    \"UTM_Y\": \"utm_y\",\n",
    "    \"UTM_X\": \"utm_x\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f153d7b4-828d-46b1-ad7d-31cb4c065847",
   "metadata": {},
   "source": [
    "### Normalize Date Time (coll_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c926be1-7f79-41a1-9323-89d9cbbd70e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tbl2[\"coll_date\"] = pd.to_datetime(\n",
    "    tbl2[\"coll_date\"],\n",
    "    format=\"%m/%d/%Y %H:%M:%S\",   # matches \"5/4/2006 0:00:00\"\n",
    "    errors=\"coerce\"\n",
    ")\n",
    "\n",
    "# Drop Time \n",
    "tbl2[\"coll_date\"] = tbl2[\"coll_date\"].dt.normalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e002a984-164f-4346-9d53-d21b320b9bb6",
   "metadata": {},
   "source": [
    "### Standardize the Column Order for Future "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "362d8d51-cba5-4b8a-bd21-3e13ae5bbd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"family\", \"genus\", \"species\",\n",
    "        \"utm_zone\", \"utm_x\", \"utm_y\", \"elev_m\",\n",
    "        \"coll_date\"]\n",
    "\n",
    "\n",
    "sanjuan = tbl2.reindex(columns=cols).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0356e7-f43d-4985-b5aa-38ab47d9eedc",
   "metadata": {},
   "source": [
    "### Save in Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c45fc34-cc56-45a9-bb9e-558ed5338fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "sanjuan.to_csv(\"SJ_Simplified_2001_2007.csv\", index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7756ee19-9f35-43fe-971b-ad2bbde10fe8",
   "metadata": {},
   "source": [
    "## North Casecades Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b284b2-8cd5-47df-ac3a-9cf78001d4c6",
   "metadata": {},
   "source": [
    "### Snake Case the Columns We are Thinking of Keeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a013be02-3989-494d-9493-a0299921a987",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_map = {\n",
    "    \"Full Scientific Name\": \"scientific_name\",\n",
    "    \"Scientific Name\": \"scientific_name\",\n",
    "    \"Family\": \"family\",\n",
    "    \"Genus\": \"genus\",\n",
    "    \"Species\": \"species\",\n",
    "    \"species\": \"species\",\n",
    "    \"Species author\": \"authority\",\n",
    "    \"Author\": \"authority\",\n",
    "    \"County\": \"county\",\n",
    "    \"State\": \"state\",\n",
    "    \"Elevation (m)\": \"elev_m\",\n",
    "    \"Elevation (meters)\": \"elev_m\",\n",
    "    \"UTM Zone\": \"utm_zone\",\n",
    "    \"UTM Z/E/N\": \"utm_zone\",\n",
    "    \"UTM Easting\": \"utm_x\",\n",
    "    \"Easting\": \"utm_x\",\n",
    "    \"UTM Northing\": \"utm_y\",\n",
    "    \"Northing\": \"utm_y\",\n",
    "    \"Lat Deg\": \"lat_deg\",\n",
    "    \"Degrees Lat\": \"lat_deg\",\n",
    "    \"Lat Min\": \"lat_min\",\n",
    "    \"Minutes Lat\": \"lat_min\",\n",
    "    \"Lat Sec\": \"lat_sec\",\n",
    "    \"Seconds Lat\": \"lat_sec\",\n",
    "    \"N or S\": \"ns\",\n",
    "    \"Long Deg\": \"long_deg\",\n",
    "    \"Degrees Long\": \"long_deg\",\n",
    "    \"Long Min\": \"long_min\",\n",
    "    \"Minutes Long\": \"long_min\",\n",
    "    \"Lon Sec\": \"lon_sec\",\n",
    "    \"Seconds Long\": \"lon_sec\",\n",
    "    \"W or E\": \"we\",\n",
    "    \"Dec Latitude\": \"latitude\",\n",
    "    \"Dec Longitude\": \"longitude\",\n",
    "    \"Collection Day\": \"coll_day\",\n",
    "    \"Collection Month\": \"coll_month\",\n",
    "    \"Collection Year\": \"coll_year\",\n",
    "}\n",
    "\n",
    "noca2002 = noca2002.rename(columns=rename_map)\n",
    "noca2003 = noca2003.rename(columns=rename_map)\n",
    "noca2004 = noca2004.rename(columns=rename_map)\n",
    "noca2005 = noca2005.rename(columns=rename_map)\n",
    "noca2006 = noca2006.rename(columns=rename_map)\n",
    "noca2007 = noca2007.rename(columns=rename_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87422c6-0d72-47c8-aa7c-5f9c671e8240",
   "metadata": {},
   "source": [
    "### Standardize Date Time Objects for all Different Syntaxes \n",
    "\n",
    "\n",
    "AI Assist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4132fb36-a9f8-4c05-b0c6-59007fc665af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_coll_date(df, day_col=\"coll_day\", month_col=\"coll_month\", year_col=\"coll_year\",\n",
    "                    out_col=\"coll_date\", add_flags=True):\n",
    "    \"\"\"\n",
    "    Create a proper datetime column from coll_day/month/year.\n",
    "    - Handles month names (\"Aug\", \"August\") and numbers (8).\n",
    "    - Fills missing month/day with 1 so dates still parse.\n",
    "    - Leaves rows with missing year as NaT.\n",
    "    - Optionally adds boolean flags for imputed month/day.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # --- Month name/abbr -> number (case-insensitive) ---\n",
    "    month_map = {m.lower(): i for i, m in enumerate(calendar.month_name) if m}\n",
    "    month_map.update({m.lower(): i for i, m in enumerate(calendar.month_abbr) if m})  # Jan, Feb, ...\n",
    "\n",
    "    # normalize month to string, strip, lower, then map; if not a name, try numeric\n",
    "    m_raw = df[month_col].astype(str).str.strip().str.lower()\n",
    "    m_num = m_raw.map(month_map)\n",
    "    m_num = pd.to_numeric(m_num, errors=\"coerce\")  # keep mapped ints; others become NaN\n",
    "    m_num = m_num.fillna(pd.to_numeric(df[month_col], errors=\"coerce\"))  # try numeric fallback\n",
    "\n",
    "    # day/year to numeric\n",
    "    d_num = pd.to_numeric(df[day_col], errors=\"coerce\")\n",
    "    y_num = pd.to_numeric(df[year_col], errors=\"coerce\")\n",
    "\n",
    "    # flags for imputation\n",
    "    month_imputed = m_num.isna()\n",
    "    day_imputed = d_num.isna()\n",
    "\n",
    "     # fill missing month/day with 1 so we can parse; keep year as-is (missing year -> NaT)\n",
    "    m_num = m_num.fillna(1).astype(\"Int64\")\n",
    "    d_num = d_num.fillna(1).astype(\"Int64\")\n",
    "\n",
    "    # build datetime; rows with NaN year will become NaT\n",
    "    df[out_col] = pd.to_datetime(\n",
    "        dict(year=y_num, month=m_num, day=d_num),\n",
    "        errors=\"coerce\"\n",
    "    )\n",
    "\n",
    "    if add_flags:\n",
    "        df[out_col + \"_month_imputed\"] = month_imputed\n",
    "        df[out_col + \"_day_imputed\"] = day_imputed\n",
    "\n",
    "    return df\n",
    "\n",
    "# ---- Apply to your NOCA frames (after your renaming to snake_case) ----\n",
    "nc02 = build_coll_date(noca2002)\n",
    "nc03 = build_coll_date(noca2003)\n",
    "nc04 = build_coll_date(noca2004)\n",
    "nc05 = build_coll_date(noca2005)\n",
    "nc06 = build_coll_date(noca2006)\n",
    "nc07 = build_coll_date(noca2007)\n",
    "\n",
    "# (Optional) if tbl2 has a string \"coll_date\" already, normalize to datetime too:\n",
    "# tbl2[\"coll_date\"] = pd.to_datetime(tbl2[\"coll_date\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ad80f1-ae29-411c-8335-7a031c943c8a",
   "metadata": {},
   "source": [
    "### Standardize the Columns for Future Combination, Matches San Juans. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d017eae2-08ab-4e5b-b10a-f6dc24f70f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"family\", \"genus\", \"species\",\n",
    "        \"utm_zone\", \"utm_x\", \"utm_y\", \"elev_m\",\n",
    "        \"coll_date\"]\n",
    "\n",
    "\n",
    "def keep(df, cols):\n",
    "    return df.reindex(columns=cols).copy()\n",
    "\n",
    "\n",
    "nc02 = keep(nc02, cols)\n",
    "nc03 = keep(nc03, cols)\n",
    "nc04 = keep(nc04, cols)\n",
    "nc05 = keep(nc05, cols)\n",
    "nc06 = keep(nc06, cols)\n",
    "nc07 = keep(nc07, cols)\n",
    "\n",
    "\n",
    "\n",
    "noca = pd.concat([nc02, nc03, nc04, nc05, nc06, nc07],\n",
    "                       ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68dc7e4-da2b-4947-88cf-82a04da083da",
   "metadata": {},
   "source": [
    "### Save In Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e625f807-8338-471a-9129-9742671c2284",
   "metadata": {},
   "outputs": [],
   "source": [
    "noca.to_csv(\"NOCA_2002_2007_simplified.csv\", index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda301fb-f653-4457-b1d8-07d11b72ee8e",
   "metadata": {},
   "source": [
    "# Prepare for Final Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84939aca-a0c9-42ad-bc08-74a32c2945f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "noca.insert(0, \"parkname\", \"noca\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "088bccb4-a126-4989-aba7-21021a98732d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sanjuan.insert(0, \"parkname\", \"sanjuan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c56886-5f6b-4c5d-b194-63650fa8c436",
   "metadata": {},
   "source": [
    "Merging Via concat or join??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be344a7-3de4-4123-a95d-1d88e7f17344",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged = pd.merge(noca, sanjuan, how='outer', on='parkname')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22e501cd-791c-4c02-9cc3-71a406610d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.concat([noca, sanjuan], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e5b6ba-82e5-44a0-85af-2aff8997e70d",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db68474-31eb-4149-b6ff-dc56576d473a",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv(\"SJ_NOCA_2001_2007.csv\", index=False, encoding=\"utf-8-sig\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
